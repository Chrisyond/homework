"""
    使用numpy实现Boston房价预测
    Step1 数据加载，来源sklearn中的load_boston
    Step2 数据规范化，将X 采用正态分布规范化
    Step3 初始化网络
    Step4 定义激活函数，损失函数，学习率 epoch
    Step5 循环执行：前向传播，计算损失函数，反向传播，参数更新
    Step6 输出训练好的model参数，即w1, w2, b1, b2
""" 
import time
import numpy as np
from sklearn.datasets import load_boston
from sklearn.utils import shuffle, resample
start = time.process_time()

# 数据加载
data = load_boston()
X_ = data['data']
y = data['target']
# 将y转化为矩阵的形式
y = y.reshape(y.shape[0],1)

# 数据规范化
X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)

"""
    初始化网络参数
    定义隐藏层维度，w1,b1,w2,b2
""" 
n_features = X_.shape[1]
n_hidden = 10
w1 = np.random.randn(n_features, n_hidden)
b1 = np.zeros(n_hidden)
w2 = np.random.randn(n_hidden, 1)
b2 = np.zeros(1)

# relu函数
def Relu(x):
    """ 这里写你的代码 """
    return np.maximum(x, 0)
    pass


# 设置学习率
learning_rate = 1e-6

# 定义损失函数
def MSE_loss(y, y_hat):
    """ 这里写你的代码 """
    return np.mean(np.square(y_hat - y))

# 定义线性回归函数
def Linear(X, W1, b1):
    """ 这里写你的代码 """
    y = W1 * X + b1
    return y

#设定初始值
current_k = 10
current_b = 10
min_loss = float('inf')
# 5000次迭代
for t in range(5000):
    # 前向传播，计算预测值y (Linear->Relu->Linear)
    """ 这里写你的代码 """
    #前向传播，输出到隐藏层
    temp = np.dot(X_, w1)
    #relu激活
    temp_relu = Relu(temp)
    # 隐藏层到输出层
    y_hat = np.dot(temp_relu, w2)
    # 计算损失函数, 并输出每次epoch的loss
    current_loss = MSE_loss(y,y_hat)
    print(t,current_loss)
    """ 这里写你的代码 """
    '''if min_loss > current_loss:
        min_loss = current_loss
        best_k,best_b = current_k,current_b
        print('best_k is {} , best_b is {}'.format(best_k,best_b))'''
    # 反向传播，基于loss 计算w1和w2的梯度
    """ 这里写你的代码 """    
    grad_y_hat = 2.0 * (y_hat - y)
    #w2梯度
    grad_w2 = np.dot(temp_relu.T, grad_y_hat)
    grad_temp_relu = np.dot(grad_y_hat, w2.T)
    grad_temp = grad_temp_relu.copy()
    #relu反向传播
    grad_temp_relu[temp<0] = 0
    #w1梯度
    grad_w1 = np.dot(X_.T,grad_temp)
    # 更新权重, 对w1, w2, b1, b2进行更新
    """ 这里写你的代码 """    
    w1 = w1 - grad_w1*learning_rate
    w2 = w2 - grad_w2*learning_rate

# 得到最终的w1, w2
end = time.process_time()
print('w1={} \n w2={}'.format(w1, w2))
print((end-start))
